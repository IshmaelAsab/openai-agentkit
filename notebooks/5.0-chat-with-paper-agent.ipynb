{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with Paper Agent\n",
    "\n",
    "In this notebook, we'll build an interactive chat interface that can answer questions about a research paper. This is like having an expert assistant who has read the paper and can explain it to you!\n",
    "\n",
    "## What You'll Learn\n",
    "- How to use the OpenAI Conversations API for stateful, multi-turn chat\n",
    "- How to give an AI agent context about a specific document\n",
    "- How to build a Q&A system for research papers\n",
    "\n",
    "## Use Case\n",
    "Research papers can be dense and difficult to understand. With this chat agent, you can:\n",
    "- Ask questions about specific sections\n",
    "- Get explanations of complex concepts in simple terms\n",
    "- Explore the paper interactively at your own pace\n",
    "\n",
    "The Conversations API automatically maintains context, so the agent remembers what you've discussed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import our libraries and set up the OpenAI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Research Paper\n",
    "\n",
    "We'll extract the text from a PDF so our agent can reference it when answering questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_text(file_path):\n",
    "    \"\"\"Loads text from a PDF file.\"\"\"\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\\n\\n\".join([page.extract_text() for page in reader.pages])\n",
    "    return text\n",
    "\n",
    "# Load the Word2Vec paper (a classic in NLP!)\n",
    "paper_text = load_pdf_text(\"../assets/paper3.pdf\")\n",
    "\n",
    "print(f\"Loaded paper with {len(paper_text)} characters\")\n",
    "print(f\"Approximately {len(paper_text.split())} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Conversation\n",
    "\n",
    "The Conversations API creates a \"conversation\" object that stores all the messages. This is perfect for chat interfaces because it automatically maintains context between turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new conversation\n",
    "conversation = client.conversations.create(\n",
    "    metadata={\"paper\": \"word2vec\", \"user_id\": \"tutorial_user\"}\n",
    ")\n",
    "\n",
    "print(f\"Created conversation with ID: {conversation.id}\")\n",
    "print(f\"Metadata: {conversation.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give the Agent Context\n",
    "\n",
    "Before asking questions, we need to \"teach\" the agent about the paper. We do this by sending the paper text as the first message with clear instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System instructions for the agent\n",
    "instructions = \"\"\"\n",
    "You are a helpful research assistant who explains academic papers in clear, simple terms.\n",
    "You have been given the full text of a research paper.\n",
    "Answer questions about the paper accurately and concisely.\n",
    "If you don't know something, say so - don't make up information.\n",
    "\"\"\"\n",
    "\n",
    "# Send the paper content to establish context\n",
    "context_response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    instructions=instructions,\n",
    "    input=f\"Here is the research paper you'll be answering questions about:\\n\\n{paper_text}\\n\\nPlease confirm you've read and understood the paper.\",\n",
    "    conversation=conversation.id\n",
    ")\n",
    "\n",
    "print(\"Agent's response:\")\n",
    "print(context_response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask Questions About the Paper\n",
    "\n",
    "Now we can have a natural conversation! Each question automatically has access to:\n",
    "1. The original paper text\n",
    "2. All previous questions and answers\n",
    "\n",
    "This is the power of the Conversations API - it handles context management for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    \"\"\"\n",
    "    Ask the agent a question about the paper.\n",
    "    The conversation ID keeps track of context automatically.\n",
    "    \"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        input=question,\n",
    "        conversation=conversation.id\n",
    "    )\n",
    "    return response.output_text\n",
    "\n",
    "# Question 1: Get a simple summary\n",
    "q1 = \"What is the main idea of this paper in one sentence?\"\n",
    "a1 = ask_question(q1)\n",
    "\n",
    "print(f\"Q: {q1}\")\n",
    "print(f\"A: {a1}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Ask about methodology\n",
    "q2 = \"How does the Skip-gram model work?\"\n",
    "a2 = ask_question(q2)\n",
    "\n",
    "print(f\"Q: {q2}\")\n",
    "print(f\"A: {a2}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: Follow-up question (tests context retention)\n",
    "q3 = \"How is that different from CBOW?\"\n",
    "a3 = ask_question(q3)\n",
    "\n",
    "print(f\"Q: {q3}\")\n",
    "print(f\"A: {a3}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4: Ask about results\n",
    "q4 = \"What were the key findings or results?\"\n",
    "a4 = ask_question(q4)\n",
    "\n",
    "print(f\"Q: {q4}\")\n",
    "print(f\"A: {a4}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Entire Conversation\n",
    "\n",
    "The Conversations API keeps a complete history. Let's retrieve and display it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the conversation history\n",
    "conversation_data = client.conversations.retrieve(conversation.id)\n",
    "\n",
    "print(f\"Conversation ID: {conversation_data.id}\")\n",
    "print(f\"Created at: {conversation_data.created_at}\")\n",
    "print(f\"Total messages: {len(conversation_data.metadata)}\")\n",
    "\n",
    "# Note: The actual message history is accessed through the responses\n",
    "# Each response in our conversation is linked through the conversation_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Full Q&A Session\n",
    "\n",
    "Let's create a nicely formatted view of our chat session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a formatted summary of the Q&A session\n",
    "qa_summary = f\"\"\"\n",
    "# Chat with Paper: Q&A Summary\n",
    "\n",
    "## Question 1\n",
    "**Q:** {q1}\n",
    "\n",
    "**A:** {a1}\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Q:** {q2}\n",
    "\n",
    "**A:** {a2}\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3\n",
    "**Q:** {q3}\n",
    "\n",
    "**A:** {a3}\n",
    "\n",
    "---\n",
    "\n",
    "## Question 4\n",
    "**Q:** {q4}\n",
    "\n",
    "**A:** {a4}\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(qa_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Your Own Questions!\n",
    "\n",
    "The conversation is still active. You can ask more questions by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask your own question!\n",
    "my_question = \"Can you explain the king - man + woman = queen example?\"\n",
    "\n",
    "my_answer = ask_question(my_question)\n",
    "\n",
    "print(f\"Q: {my_question}\")\n",
    "print(f\"A: {my_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Conversations API**: Use `conversations.create()` to maintain stateful chat sessions\n",
    "2. **Context Management**: The API automatically remembers all previous messages, so follow-up questions work naturally\n",
    "3. **Document Q&A**: By sending document content as initial context, you can build specialized assistants for any text\n",
    "\n",
    "## When to Use Conversations API vs Responses API\n",
    "\n",
    "**Use Conversations API when:**\n",
    "- Building chat interfaces with multiple turns\n",
    "- You need automatic context/history management\n",
    "- Users will have back-and-forth conversations\n",
    "\n",
    "**Use Responses API with `previous_response_id` when:**\n",
    "- You want more control over context\n",
    "- Building simple question-answer flows\n",
    "- You need to manage context yourself\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Try:\n",
    "- Loading different papers and comparing them\n",
    "- Building a web interface around this Q&A system\n",
    "- Adding citation extraction to show which part of the paper the answer comes from"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
